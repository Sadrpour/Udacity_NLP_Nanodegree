{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# RUN THIS CODE CELL IF YOU ARE RESUMING THE NOTEBOOK AFTER A BREAK #\n",
    "#####################################################################\n",
    "\n",
    "# allocate 50% of GPU memory (if you like, feel free to change this)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf \n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "# set_session(tf.Session(config=config))\n",
    "\n",
    "# watch for any changes in the sample_models module, and reload it automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# import NN architectures for speech recognition\n",
    "from sample_models import *\n",
    "# import function for training acoustic model\n",
    "from train_utils import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, None, 161)         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 512)         907264    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "bn_conv_1d (BatchNormalizati (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 1024)        3148800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "rnn_dropout0 (Dropout)       (None, None, 1024)        0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 1024)        4721664   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "rnn_dropout1 (Dropout)       (None, None, 1024)        0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, None, 1024)        4721664   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "rnn_dropout2 (Dropout)       (None, None, 1024)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 29)          29725     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 13,543,453\n",
      "Trainable params: 13,536,285\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# specify the model\n",
    "model_end = final_model(input_dim=161,units=512,recur_layers=3) \n",
    "\n",
    "# model_end = model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/pemfir/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n",
      "101/101 [==============================] - 124s 1s/step - loss: 238.3555 - val_loss: 211.6380\n",
      "Epoch 2/20\n",
      "101/101 [==============================] - 122s 1s/step - loss: 199.7134 - val_loss: 190.2719\n",
      "Epoch 3/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 179.3932 - val_loss: 169.9347\n",
      "Epoch 4/20\n",
      "101/101 [==============================] - 124s 1s/step - loss: 165.4828 - val_loss: 159.0617\n",
      "Epoch 5/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 154.4504 - val_loss: 149.3550\n",
      "Epoch 6/20\n",
      "101/101 [==============================] - 122s 1s/step - loss: 143.8905 - val_loss: 145.2875\n",
      "Epoch 7/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 134.8992 - val_loss: 140.8590\n",
      "Epoch 8/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 125.7273 - val_loss: 136.4269\n",
      "Epoch 9/20\n",
      "101/101 [==============================] - 122s 1s/step - loss: 118.3553 - val_loss: 135.2969\n",
      "Epoch 10/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 110.6306 - val_loss: 131.9697\n",
      "Epoch 11/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 103.3334 - val_loss: 130.8172\n",
      "Epoch 12/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 96.6487 - val_loss: 132.1722\n",
      "Epoch 13/20\n",
      "101/101 [==============================] - 122s 1s/step - loss: 90.5471 - val_loss: 130.8768\n",
      "Epoch 14/20\n",
      "101/101 [==============================] - 122s 1s/step - loss: 84.6292 - val_loss: 133.2583\n",
      "Epoch 15/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 78.5661 - val_loss: 136.3368\n",
      "Epoch 16/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 73.6350 - val_loss: 136.2038\n",
      "Epoch 17/20\n",
      "101/101 [==============================] - 122s 1s/step - loss: 68.6943 - val_loss: 131.1407\n",
      "Epoch 18/20\n",
      "101/101 [==============================] - 122s 1s/step - loss: 64.4530 - val_loss: 133.9176\n",
      "Epoch 19/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 60.9094 - val_loss: 139.0033\n",
      "Epoch 20/20\n",
      "101/101 [==============================] - 123s 1s/step - loss: 57.1189 - val_loss: 138.1914\n"
     ]
    }
   ],
   "source": [
    "train_model(input_to_softmax=model_end, \n",
    "            pickle_path='model_end.pickle', \n",
    "            save_model_path='model_end.h5', \n",
    "            spectrogram=True) # change to False if you would like to use MFCC features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2:__ Describe your final model architecture and your reasoning at each step.  \n",
    "\n",
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## STEP 3: Obtain Predictions\n",
    "\n",
    "We have written a function for you to decode the predictions of your acoustic model.  To use the function, please execute the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_generator import AudioGenerator\n",
    "from keras import backend as K\n",
    "from utils import int_sequence_to_text\n",
    "from IPython.display import Audio\n",
    "\n",
    "def get_predictions(index, partition, input_to_softmax, model_path):\n",
    "    \"\"\" Print a model's decoded predictions\n",
    "    Params:\n",
    "        index (int): The example you would like to visualize\n",
    "        partition (str): One of 'train' or 'validation'\n",
    "        input_to_softmax (Model): The acoustic model\n",
    "        model_path (str): Path to saved acoustic model's weights\n",
    "    \"\"\"\n",
    "    # load the train and test data\n",
    "    data_gen = AudioGenerator()\n",
    "    data_gen.load_train_data()\n",
    "    data_gen.load_validation_data()\n",
    "    \n",
    "    # obtain the true transcription and the audio features \n",
    "    if partition == 'validation':\n",
    "        transcr = data_gen.valid_texts[index]\n",
    "        audio_path = data_gen.valid_audio_paths[index]\n",
    "        data_point = data_gen.normalize(data_gen.featurize(audio_path))\n",
    "    elif partition == 'train':\n",
    "        transcr = data_gen.train_texts[index]\n",
    "        audio_path = data_gen.train_audio_paths[index]\n",
    "        data_point = data_gen.normalize(data_gen.featurize(audio_path))\n",
    "    else:\n",
    "        raise Exception('Invalid partition!  Must be \"train\" or \"validation\"')\n",
    "        \n",
    "    # obtain and decode the acoustic model's predictions\n",
    "    input_to_softmax.load_weights(model_path)\n",
    "    prediction = input_to_softmax.predict(np.expand_dims(data_point, axis=0))\n",
    "    output_length = [input_to_softmax.output_length(data_point.shape[0])] \n",
    "    pred_ints = (K.eval(K.ctc_decode(\n",
    "                prediction, output_length)[0][0])+1).flatten().tolist()\n",
    "    \n",
    "    # play the audio file, and display the true and predicted transcriptions\n",
    "    print('-'*80)\n",
    "    Audio(audio_path)\n",
    "    print('True transcription:\\n' + '\\n' + transcr)\n",
    "    print('-'*80)\n",
    "    print('Predicted transcription:\\n' + '\\n' + ''.join(int_sequence_to_text(pred_ints)))\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code cell below to obtain the transcription predicted by your final model for the first example in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, None, 161)         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 512)         907264    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "bn_conv_1d (BatchNormalizati (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 400)         855600    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 400)         1600      \n",
      "_________________________________________________________________\n",
      "rnn_dropout0 (Dropout)       (None, None, 400)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, None, 400)         721200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, 400)         1600      \n",
      "_________________________________________________________________\n",
      "rnn_dropout1 (Dropout)       (None, None, 400)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 29)          11629     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 2,500,941\n",
      "Trainable params: 2,498,317\n",
      "Non-trainable params: 2,624\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 9 layers into a model with 7 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4522ac92b43f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                 \u001b[0mpartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0minput_to_softmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m161\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecur_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 model_path='./results/model_end.h5')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-1adf2a41110d>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(index, partition, input_to_softmax, model_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# obtain and decode the acoustic model's predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0minput_to_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_to_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moutput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_to_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1166\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1028\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 9 layers into a model with 7 layers."
     ]
    }
   ],
   "source": [
    "get_predictions(index=0, \n",
    "                partition='train',\n",
    "                input_to_softmax=final_model(input_dim=161,units=200,recur_layers=2)  , \n",
    "                model_path='./results/model_end.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to visualize the model's prediction for the first example in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(index=0, \n",
    "                partition='validation',\n",
    "                input_to_softmax=final_model(input_dim=161,units=200,recur_layers=2) , \n",
    "                model_path='./results/model_end.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "907264/(512*161)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
