{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'the', 'old', 'man', 'spoke', 'to', 'me', '</s>']\n",
      "[('<s>', 'the'), ('the', 'old'), ('old', 'man'), ('man', 'spoke'), ('spoke', 'to'), ('to', 'me'), ('me', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import bigrams\n",
    "\n",
    "test_sentences = [\n",
    "    'the old man spoke to me',\n",
    "    'me to spoke man old the',\n",
    "    'old man me old man me',\n",
    "]\n",
    "\n",
    "\n",
    "sentence_tokens = ['<s>'] + word_tokenize(test_sentences[0]) + ['</s>']\n",
    "sentence_bigrams = bigrams(sentence_tokens)\n",
    "print(sentence_tokens)\n",
    "print([b for b in sentence_bigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pemfir/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<s>', 'the', 'old', 'man', 'spoke', 'to', 'me', '</s>'],\n",
       " [('<s>', 'the'),\n",
       "  ('the', 'old'),\n",
       "  ('old', 'man'),\n",
       "  ('man', 'spoke'),\n",
       "  ('spoke', 'to'),\n",
       "  ('to', 'me'),\n",
       "  ('me', '</s>')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_to_bigrams_simple(sentence):\n",
    "    \"\"\"\n",
    "    Add start '<s>' and stop '</s>' tags to the sentence and tokenize it into a list\n",
    "    of lower-case words (sentence_tokens) and bigrams (sentence_bigrams)\n",
    "    :param sentence: string\n",
    "    :return: list, list\n",
    "        sentence_tokens: ordered list of words found in the sentence\n",
    "        sentence_bigrams: a list of ordered two-word tuples found in the sentence\n",
    "    \"\"\"\n",
    "    #TODO implement\n",
    "    sentence_tokens = ['<s>'] + sentence.split(\" \") + ['</s>']\n",
    "    sentence_bigrams = list()\n",
    "    for i in range(len(sentence_tokens)-1):\n",
    "        sentence_bigrams.append((sentence_tokens[i],sentence_tokens[i+1]))\n",
    "    return sentence_tokens, sentence_bigrams\n",
    "\n",
    "\n",
    "sentence_to_bigrams_simple('the old man spoke to me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'i': 2, 'am': 2, '<s>': 1, 'as': 1, '</s>': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Sentence: \"I am as I am\"\n",
    "tokens = ['<s>', 'i', 'am', 'as', 'i', 'am', '</s>']\n",
    "token_counts = Counter(tokens)\n",
    "print(token_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import utils\n",
    "\n",
    "\n",
    "def sample_run():\n",
    "    # sample usage by test code (this definition not actually run for the quiz)\n",
    "    tokens, bigrams = utils.bigrams_from_transcript('transcripts.txt')\n",
    "    bg_dict = bigram_mle(tokens, bigrams)\n",
    "    print(bg_dict)\n",
    "\n",
    "\n",
    "def bigram_mle(tokens, bigrams):\n",
    "    \"\"\"\n",
    "    provide a dictionary of probabilities for all bigrams in a corpus of text\n",
    "    the calculation is based on maximum likelihood estimation and does not include\n",
    "    any smoothing.  A tag '<unk>' has been added for unknown probabilities.\n",
    "    :param tokens: list\n",
    "        tokens: list of all tokens in the corpus\n",
    "    :param bigrams: list\n",
    "        bigrams: list of all two word tuples in the corpus\n",
    "    :return: dict\n",
    "        bg_mle_dict: a dictionary of bigrams:\n",
    "            key: tuple of two bigram words, in order OR <unk> key\n",
    "            value: float probability\n",
    "\n",
    "    \"\"\"\n",
    "    bg_mle_dict = {}\n",
    "    bg_mle_dict['<unk>'] = 0.\n",
    "    #TODO implement\n",
    "    return bg_mle_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('old', 'man') 1\n",
      "1.0\n",
      "('only', 'spoke') 1\n",
      "1.0\n",
      "('me', 'only') 1\n",
      "0.5\n",
      "('spoke', 'to') 1\n",
      "0.5\n",
      "('man', 'spoke') 1\n",
      "1.0\n",
      "('spoke', 'me') 1\n",
      "0.5\n",
      "('to', 'me') 1\n",
      "1.0\n",
      "('me', '</s>') 1\n",
      "0.5\n",
      "('the', 'old') 1\n",
      "1.0\n",
      "('<s>', 'the') 1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "unigrams, bigrams = sentence_to_bigrams_simple('the old man spoke to me only spoke me')\n",
    "unigram_count = Counter(unigrams)\n",
    "bigram_count = Counter(bigrams)\n",
    "for tuple_, count_ in bigram_count.items():\n",
    "    print(tuple_, count_)\n",
    "    print(count_/unigram_count[tuple_[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
